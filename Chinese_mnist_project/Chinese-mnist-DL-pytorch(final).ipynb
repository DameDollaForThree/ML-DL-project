{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nfrom skimage import io, transform\n\ntrain_data = pd.read_csv('../input/chinese-mnist/chinese_mnist.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a helper function\ndef create_file_name(x):\n    \n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"file_name\"] = train_data.apply(create_file_name, axis=1)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(15000):\n    if train_data['value'][i] == 100:\n        train_data['value'][i] = 11\n    elif train_data['value'][i] == 1000:\n        train_data['value'][i] = 12\n    elif train_data['value'][i] == 10000:\n        train_data['value'][i] = 13\n    elif train_data['value'][i] == 100000000:\n        train_data['value'][i] = 14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nnew_train, new_test = train_test_split(\n     train_data, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_train)\nprint(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.to_csv('new_train_file.csv', index=False)\nnew_test.to_csv('new_test_file.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ChineseMnistDataset(torch.utils.data.Dataset):\n    \"\"\"Dataset wrapping images and target labels for Chinese_mnist\n\n    Arguments:\n        A CSV file path\n        Path to image folder\n        Optional transform to be applied on a sample.\n    \"\"\"\n    def __init__(self, csv_file, root_dir, transform=None):\n        \n        self.label_frame = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.label_frame)\n    \n    def __getitem__(self, index):\n        if torch.is_tensor(index):\n            index = index.tolist()\n            \n        # image    \n#         print(\"I am inside the getitem function\")\n        img_name = os.path.join(self.root_dir, self.label_frame['file_name'].loc[index])\n        image = io.imread(img_name)\n#         print(image)\n        \n        # label\n        label = self.label_frame['value'].loc[index]\n#         print(label)\n\n        sample = (image, label)\n        if self.transform:\n            sample = (self.transform(image), torch.tensor(label))\n            \n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\ntrainset = ChineseMnistDataset(csv_file='new_train_file.csv',\n                                    root_dir='../input/chinese-mnist/data/data/', transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(trainloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time iter(trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter(trainloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The function to show an image.\ndef imshow(img):\n    img = img / 2 + 0.5     # Unnormalize.\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Get some random training images.\ndataiter = iter(trainloader)\nfor i in range(2):\n    images, labels = next(dataiter)\n    \n    # Show images.\n    imshow(torchvision.utils.make_grid(images))\n    # Print labels.\n    print(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n        self.conv2 = nn.Conv2d(64, 20, 3, padding=1)\n        self.fc1 = nn.Linear(5120, 100)\n        self.fc2 = nn.Linear(100, 15)\n        \n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \n    \nnet = Net()     # Create the network instance.\nnet.to(device)  # Move the network parameters to the specified device.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use cross-entropy as loss function.\nloss_func = nn.CrossEntropyLoss()  \n# We use stochastic gradient descent (SGD) as optimizer.\nopt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_losses = []   # Avg. losses.\nepochs = 5       # Total epochs.\nprint_freq = 100  # Print frequency.\n\nfor epoch in range(epochs):  # Loop over the dataset multiple times.\n    \n    running_loss = 0.0       # Initialize running loss.\n    \n\n    for i, data in enumerate(trainloader, 0):\n        \n        # Get the inputs.\n        inputs, labels = data\n        \n        # Move the inputs to the specified device.\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Zero the parameter gradients.\n        opt.zero_grad()\n\n        # Forward step.\n#         inputs = inputs.unsqueeze(0)\n        outputs = net(inputs)\n#         labels = labels.view(1)\n        loss = loss_func(outputs, labels)\n        \n        # Backward step.\n        loss.backward()\n        \n        # Optimization step (update the parameters).\n        opt.step()\n\n        # Print statistics.\n        running_loss += loss.item()\n        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n            avg_loss = running_loss / print_freq\n            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n                epoch, i, avg_loss))\n            avg_losses.append(avg_loss)\n            running_loss = 0.0\n\n\n\n            \n            \nprint('Finished Training.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(avg_losses)\nplt.xlabel('mini-batch index / {}'.format(print_freq))\nplt.ylabel('avg. mini-batch loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset = ChineseMnistDataset(csv_file='new_test_file.csv',\n                                    root_dir='../input/chinese-mnist/data/data/', transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, num_workers=2)\n\n# Check several images.\n\ndataiter = iter(testloader)\nimages, labels = next(dataiter)\n# Show images.\nimshow(torchvision.utils.make_grid(images))\n\nprint(labels)\n\noutputs = net(images.to(device))\n_, predicted = torch.max(outputs, 1)\n\nprint(predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get test accuracy.\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (\n    100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}